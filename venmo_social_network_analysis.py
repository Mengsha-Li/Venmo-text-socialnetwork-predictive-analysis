# -*- coding: utf-8 -*-
"""Venmo_social_network_analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HooVFsJxaA6GeeNetWHVgPeb7-fEyL1b

### Social Network Analytics
"""

# Import Venmo data
# from pyspark.sql import SparkSession
venmo=spark.read.parquet('/FileStore/tables/venmo/VenmoSample_snappy-e020d.parquet')
venmo.show(5)

venmo.createOrReplaceTempView("VenmoSample")

"""d
#### find a user’s friends and friends of friends (Friend definition: A user’s friend is someone who has transacted with the user, either sending money to the user or receiving money from the user).
"""

# Commented out IPython magic to ensure Python compatibility.
# %sql
create table default.venmo_nw
as
WITH temp1 AS 
( 
                SELECT DISTINCT *,
                                cast(MONTHS_BETWEEN(datetime, min(datetime) over 
                                (partition by user1 order by datetime)) as INT) as life_month
                FROM            ( 
                                       SELECT a.user1, 
                                              a.user2,
                                              a.datetime
                                       FROM   `venmosample` a 
                                       UNION 
                                       SELECT b.user2 AS user1, 
                                              b.user1 AS user2,
                                              b.datetime
                                       FROM   `venmosample` b))
SELECT a.user1,
       a.user2,
       a.datetime AS dt,
       a.life_month,
       1 AS degree 
FROM   temp1 a 
UNION
SELECT *
FROM (
SELECT distinct b.user1, 
                c.user2, 
                case when b.datetime < c.datetime then null
                     else b.datetime end as dt, /*2nd connection built after 1st firends connected with 2nd firends*/
                b.life_month, 
                2 AS degree
FROM      temp1 b 
LEFT JOIN temp1 c 
ON        b.user2 = c.user1 
LEFT JOIN temp1 d
ON        b.user1 = d.user1
AND       c.user2 = d.user2
WHERE b.user1 <> c.user2 /* exclude duplicates in this table */
AND d.user1 is null /* exclude 1st connections in this table */)
WHERE dt is not null
ORDER BY  user1, 
          degree,
          user2,
          dt

"""#### calculate social network variables, using the dynamic analysis from before from 0 up to 12 months)."""

# Commented out IPython magic to ensure Python compatibility.
# %sql
create table default.network
as(
select user1,user2,CAST( MONTHS_BETWEEN(datetime, FIRST_VALUE(datetime) OVER (PARTITION BY user1 ORDER BY datetime))+ 1 as INT) as month
from default.venmo_nw);

-- drop table default.venmo_nw;

create table default.venmo_nw
as (
select * from default.network
where month <= 12)

"""- 1. Number of friends and number of friends of friends"""

# Commented out IPython magic to ensure Python compatibility.
# %sql
create table default.venmo_nw_dynamic
as
select a.*
from default.venmo_nw a
where life_month < 13
order by user1, degree, dt

# Commented out IPython magic to ensure Python compatibility.
# %sql
drop table default.friends;

create table default.friends as
(
select a.user1, a.life_month as month, cum_f as friends, cum_fof as mutual_friends from (select distinct user1, 
       life_month, 
       sum(count(user2) over (partition by user1, life_month)) over (partition by user1 order by life_month) as cum_f
from default.venmo_nw_dynamic
where degree = 1
order by 1,2) as a
left join (select distinct user1, 
       life_month, 
       sum(count(user2) over (partition by user1, life_month)) over (partition by user1 order by life_month) as cum_fof
from default.venmo_nw_dynamic
where degree = 2
order by 1,2) as b
on a.user1 = b.user1
and a.life_month = b.life_month)

"""- 2.Clustering coefficient of a user's network"""

# Commented out IPython magic to ensure Python compatibility.
# %sql
create table default.all_conn as
(
select a.user1, a.user2 as friend, b.user2 as mutual_friends, a.life_month as month
from default.venmo_nw_dynamic as a
left join default.venmo_nw_dynamic as b
on a.user2 = b.user1
where a.degree = 1
order by user1, friend
)

from pyspark.sql.functions import array, collect_list, flatten, udf, desc, asc, lit
from pyspark.sql.types import StringType, ArrayType, IntegerType, FloatType, MapType

mutual_friends = collect_list("mutual_friends").alias("mutual_friends")
friends = collect_list("friend").alias("friends")
append_udf = udf(lambda x,y: {a:b for a,b in zip(x,y)}, MapType(IntegerType(),ArrayType(IntegerType())))

for month in range(0,13):
  users_df = spark.sql('select distinct user1, friend, mutual_friends from default.all_conn where month = %s'%month)
  user_network = users_df.groupBy("user1","friend").agg(mutual_friends).orderBy(asc("user1"), asc('friend'))
  user_network_coalesced = user_network.groupBy('user1').agg(mutual_friends,friends).orderBy(asc('user1')).select('user1',lit(month).alias('month'),'friends','mutual_friends')
#   all_conn = user_network_coalesced.withColumn('friends_dict', append_udf('friends','mutual_friends')).select('user1',lit(month).alias('month'),'friends_dict')
  if month == 0:
    consolidated_df = user_network_coalesced
  else:
    consolidated_df = consolidated_df.union(user_network_coalesced)

def coeff(x,y):
  '''
  formula for clustering coeff:  number of connections among friends/(k*(k-1)/2)
  '''
#   friends = x.keys()
  k = len(x)
  den = k*(k-1)/2
  if den == 0:
    den = 1
  num = []
  for friend, mutual in zip(x,y):
    x_conns = [a+friend for a in x if a in mutual and a+friend not in num]
    num = num+x_conns
  return (len(num)/den)
clustering_coeff_udf=udf(lambda x,y: coeff(x,y), FloatType())
clustering_coeff = consolidated_df.withColumn('ClusteringCoef',clustering_coeff_udf('friends','mutual_friends'))

clustering_coeff.select('user1','month','ClusteringCoef').createOrReplaceTempView('clustering')

# Commented out IPython magic to ensure Python compatibility.
# %sql
create table clustering as
(
select * from clustering)

# Commented out IPython magic to ensure Python compatibility.
# %sql 
select * from default.clustering 
where ClusteringCoef <> 1
order by ClusteringCoef desc
limit 10

"""- 3 Calculate the page rank of each user"""

#maven installation coordinates---> graphframes:graphframes:0.8.0-spark2.4-s_2.11
from graphframes import GraphFrame

for month in range(0,13):

  # Create a GraphFrame
  data = spark.sql(""" SELECT DISTINCT user1, user2
                       FROM default.venmo_nw_dynamic
                       where degree = 1
                       and life_month = %s"""%month)
  vertices = data.select('user1').withColumnRenamed('user1', 'id').distinct()
  edges = data.withColumnRenamed('user1', 'src').withColumnRenamed('user2', 'dst')
  g = GraphFrame(vertices, edges)
  # Run PageRank algorithm, and show results.
  results = g.pageRank(resetProbability=0.01, maxIter=1)
  temp = results.vertices.withColumnRenamed('id','user1').select("user1",lit(month).alias('month'), "pagerank")
  if month == 0:
    dff = temp
  else:
    dff = dff.union(temp)

dff.createOrReplaceTempView('pagerank')

# Commented out IPython magic to ensure Python compatibility.
# %sql
drop table if exists default.pagerank;

create table default.pagerank as
(select * from pagerank)

df = spark.sql('select a.*, b.ClusteringCoef from default.friends as a left join default.clustering as b on a.user1 = b.user1 and a.month = b.month left join pagerank as c on a.user1 = c.user1 and a.month = c.month')
df.repartition(1).write.parquet("/FileStore/tables/venmo/friends_clustering_pagerank.parquet")

dbutils.fs.ls('/FileStore/tables/venmo/friends_clustering_pagerank.parquet')
#https://community.cloud.databricks.com/files/tables/venmo/friends_clustering_pagerank.parquet/part-00000-tid-1699215332048430463-a257aef9-c578-4a26-ac2f-5aea4cfffcec-53186-1-c000.snappy.parquet?o=8754503598138